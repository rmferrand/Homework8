[
  {
    "objectID": "Modeling.html",
    "href": "Modeling.html",
    "title": "Modeling",
    "section": "",
    "text": "Purpose: This program seeks to complete the exercises listed in Homework 8, for ST558. This homework uses basic modeling practices, including exploratory data analysis and test and training data splits. After validating the necessary data frames and data points, we plot to see relationships between predictors and the response variable. Then, we split the data and analyze 3 different models concerning these predictors and response.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(lubridate)\nlibrary(corrplot)\nset.seed(558)\n\n\nseoulbike &lt;- read_csv(\"SeoulBikeData.csv\", locale=locale(encoding=\"latin1\"))\n\n\nTask 1: Validate The Data\nValidating the data is an important precursor to making sure that everything that we have lines up. If we didn’t do this in application, we may find that we would get some unexpected results!\n\nChecking for missing values\n\nsum(is.na(seoulbike))\n\n[1] 0\n\n\nWe have no missing values! Excellent.\n\n\nTypes of Variables\nUsing the tibble function, we can see all of the values and types of the variables.\n\nas_tibble(seoulbike, width = Inf)\n\n# A tibble: 8,760 × 14\n   Date       `Rented Bike Count`  Hour `Temperature(°C)` `Humidity(%)`\n   &lt;chr&gt;                    &lt;dbl&gt; &lt;dbl&gt;             &lt;dbl&gt;         &lt;dbl&gt;\n 1 01/12/2017                 254     0              -5.2            37\n 2 01/12/2017                 204     1              -5.5            38\n 3 01/12/2017                 173     2              -6              39\n 4 01/12/2017                 107     3              -6.2            40\n 5 01/12/2017                  78     4              -6              36\n 6 01/12/2017                 100     5              -6.4            37\n 7 01/12/2017                 181     6              -6.6            35\n 8 01/12/2017                 460     7              -7.4            38\n 9 01/12/2017                 930     8              -7.6            37\n10 01/12/2017                 490     9              -6.5            27\n# ℹ 8,750 more rows\n# ℹ 9 more variables: `Wind speed (m/s)` &lt;dbl&gt;, `Visibility (10m)` &lt;dbl&gt;,\n#   `Dew point temperature(°C)` &lt;dbl&gt;, `Solar Radiation (MJ/m2)` &lt;dbl&gt;,\n#   `Rainfall(mm)` &lt;dbl&gt;, `Snowfall (cm)` &lt;dbl&gt;, Seasons &lt;chr&gt;, Holiday &lt;chr&gt;,\n#   `Functioning Day` &lt;chr&gt;\n\n\nMost of these make sense, but we have a few values we should probably convert to factors. Let’s do that first:\n\n\nConvert Character To Factor\n\nseoulbike$Seasons &lt;- as.factor(seoulbike$Seasons)\nseoulbike$Holiday &lt;- as.factor(seoulbike$Holiday)\nseoulbike$`Functioning Day` &lt;- as.factor(seoulbike$`Functioning Day`)\nseoulbike$Date &lt;- dmy(seoulbike$Date)\n\nNow let’s view the data again before we do any summaries:\n\nas_tibble(seoulbike, width = Inf)\n\n# A tibble: 8,760 × 14\n   Date       `Rented Bike Count`  Hour `Temperature(°C)` `Humidity(%)`\n   &lt;date&gt;                   &lt;dbl&gt; &lt;dbl&gt;             &lt;dbl&gt;         &lt;dbl&gt;\n 1 2017-12-01                 254     0              -5.2            37\n 2 2017-12-01                 204     1              -5.5            38\n 3 2017-12-01                 173     2              -6              39\n 4 2017-12-01                 107     3              -6.2            40\n 5 2017-12-01                  78     4              -6              36\n 6 2017-12-01                 100     5              -6.4            37\n 7 2017-12-01                 181     6              -6.6            35\n 8 2017-12-01                 460     7              -7.4            38\n 9 2017-12-01                 930     8              -7.6            37\n10 2017-12-01                 490     9              -6.5            27\n# ℹ 8,750 more rows\n# ℹ 9 more variables: `Wind speed (m/s)` &lt;dbl&gt;, `Visibility (10m)` &lt;dbl&gt;,\n#   `Dew point temperature(°C)` &lt;dbl&gt;, `Solar Radiation (MJ/m2)` &lt;dbl&gt;,\n#   `Rainfall(mm)` &lt;dbl&gt;, `Snowfall (cm)` &lt;dbl&gt;, Seasons &lt;fct&gt;, Holiday &lt;fct&gt;,\n#   `Functioning Day` &lt;fct&gt;\n\n\nEverything looks like it makes sense!\n\n\nSummary Statistics and Levels\nLet’s now validate the range of values and summary statistics that all of the numeric and character variables have. This will let us see if there are any weird things going on in the data.\n\nseoulbike |&gt;\n  select(where(is.numeric)) |&gt;\n  summary()\n\n Rented Bike Count      Hour       Temperature(°C)   Humidity(%)   \n Min.   :   0.0    Min.   : 0.00   Min.   :-17.80   Min.   : 0.00  \n 1st Qu.: 191.0    1st Qu.: 5.75   1st Qu.:  3.50   1st Qu.:42.00  \n Median : 504.5    Median :11.50   Median : 13.70   Median :57.00  \n Mean   : 704.6    Mean   :11.50   Mean   : 12.88   Mean   :58.23  \n 3rd Qu.:1065.2    3rd Qu.:17.25   3rd Qu.: 22.50   3rd Qu.:74.00  \n Max.   :3556.0    Max.   :23.00   Max.   : 39.40   Max.   :98.00  \n Wind speed (m/s) Visibility (10m) Dew point temperature(°C)\n Min.   :0.000    Min.   :  27     Min.   :-30.600          \n 1st Qu.:0.900    1st Qu.: 940     1st Qu.: -4.700          \n Median :1.500    Median :1698     Median :  5.100          \n Mean   :1.725    Mean   :1437     Mean   :  4.074          \n 3rd Qu.:2.300    3rd Qu.:2000     3rd Qu.: 14.800          \n Max.   :7.400    Max.   :2000     Max.   : 27.200          \n Solar Radiation (MJ/m2)  Rainfall(mm)     Snowfall (cm)    \n Min.   :0.0000          Min.   : 0.0000   Min.   :0.00000  \n 1st Qu.:0.0000          1st Qu.: 0.0000   1st Qu.:0.00000  \n Median :0.0100          Median : 0.0000   Median :0.00000  \n Mean   :0.5691          Mean   : 0.1487   Mean   :0.07507  \n 3rd Qu.:0.9300          3rd Qu.: 0.0000   3rd Qu.:0.00000  \n Max.   :3.5200          Max.   :35.0000   Max.   :8.80000  \n\nunique(seoulbike$Seasons)\n\n[1] Winter Spring Summer Autumn\nLevels: Autumn Spring Summer Winter\n\nunique(seoulbike$Holiday)\n\n[1] No Holiday Holiday   \nLevels: Holiday No Holiday\n\nunique(seoulbike$`Functioning Day`)\n\n[1] Yes No \nLevels: No Yes\n\n\nAll of these seem to make sense, Rainfall of 35 might be an outlier so we can investigate:\n\nplot(seoulbike$`Rainfall(mm)`)\n\n\n\n\nDoes not appear to be an outlier, the dataset is just heavy on zeroes. It’s good practice to investigate, though!\n\n\nRename Variables\n\nseoulbike &lt;- seoulbike |&gt;\n  rename(Temp = `Temperature(°C)`,\n         Humidity = `Humidity(%)`,\n         WindSpeed = `Wind speed (m/s)`,\n         Visibility = `Visibility (10m)`,\n         RentedBikeCount = `Rented Bike Count`,\n         DewTemp = `Dew point temperature(°C)`,\n         SolarRad = `Solar Radiation (MJ/m2)`,\n         Rainfall = `Rainfall(mm)`,\n         Snowfall = `Snowfall (cm)`,\n         FuncDay = `Functioning Day`\n         )\n\nExcellent, this will make our coding much more seamless.\n\n\nComplex Summary Statistics\nNow let’s make our summary statistics more complex and across the factors. This will allow us to see if there are any trends in the data we should be worried about or keep in mind while we model.\n\nnum_sum_seasons &lt;- seoulbike |&gt;\n  group_by(Seasons) |&gt;\n  summarise(across(where(is.numeric), \n    list(\n      Min = ~min(. , na.rm = TRUE),\n      Max = ~max(. , na.rm = TRUE),\n      Mean = ~mean(. , na.rm = TRUE),\n      Median = ~median(. , na.rm = TRUE),\n      SD = ~sd(. , na.rm = TRUE),\n      IQR = ~IQR(. , na.rm = TRUE)), \n      .names = \"{.col}_{.fn}\")) |&gt;\n  pivot_longer(cols = -Seasons, names_to = c(\"Variable\", \".value\"), \n    names_sep = \"_\")\n\n\nnum_sum_holiday &lt;- seoulbike |&gt;\n  group_by(Holiday) |&gt;\n  summarise(across(where(is.numeric), \n    list(\n      Min = ~min(. , na.rm = TRUE),\n      Max = ~max(. , na.rm = TRUE),\n      Mean = ~mean(. , na.rm = TRUE),\n      Median = ~median(. , na.rm = TRUE),\n      SD = ~sd(. , na.rm = TRUE),\n      IQR = ~IQR(. , na.rm = TRUE)), \n      .names = \"{.col}_{.fn}\")) |&gt;\n  pivot_longer(cols = -Holiday, names_to = c(\"Variable\", \".value\"), \n    names_sep = \"_\")\n\n\nnum_sum_funcday &lt;- seoulbike |&gt;\n  group_by(FuncDay) |&gt;\n  summarise(across(where(is.numeric), \n    list(\n      Min = ~min(. , na.rm = TRUE),\n      Max = ~max(. , na.rm = TRUE),\n      Mean = ~mean(. , na.rm = TRUE),\n      Median = ~median(. , na.rm = TRUE),\n      SD = ~sd(. , na.rm = TRUE),\n      IQR = ~IQR(. , na.rm = TRUE),\n      nObs = ~sum(!is.na(.x))),\n      .names = \"{.col}_{.fn}\")) |&gt;\n  pivot_longer(cols = -FuncDay, names_to = c(\"Variable\", \".value\"), \n    names_sep = \"_\")\n\nSo what I’m noticing for the FuncDay variable is that the rented bike count and snowfall is 0 for all 295 observations when FuncDay == No. I don’t know if this is what we are supposed to “notice” and “subset” on, but in the field I would be very hesitant to just remove 295 data points. All analysis going forward will be conditional on the fact that FuncDay == Yes only.\n\n\nSummarize Across Hours\nLet’s group this with number 7, summarizing across hours. Then we will go ahead and create new summary statistics.\n\nseoulbike_new &lt;- seoulbike |&gt;\n  filter(FuncDay == \"Yes\") |&gt;\n  group_by(Date, Seasons, Holiday) |&gt;\n  summarise(\n    RentedBikeCount = sum(RentedBikeCount),\n    Rainfall = sum(Rainfall),\n    Snowfall = sum(Snowfall),\n    Temp = mean(Temp),\n    Humidity = mean(Humidity),\n    WindSpeed = mean(WindSpeed),\n    Visibility = mean(Visibility),\n    DewTemp = mean(DewTemp),\n    SolarRad = mean(SolarRad),\n    .groups = \"keep\"\n  )\n\n\n\nFinal Summary Statistics of Explored Data\n\nseoulbike_new |&gt;\n  summary()\n\n      Date              Seasons         Holiday    RentedBikeCount\n Min.   :2017-12-01   Autumn:81   Holiday   : 17   Min.   :  977  \n 1st Qu.:2018-02-27   Spring:90   No Holiday:336   1st Qu.: 6967  \n Median :2018-05-28   Summer:92                    Median :18563  \n Mean   :2018-05-28   Winter:90                    Mean   :17485  \n 3rd Qu.:2018-08-24                                3rd Qu.:26285  \n Max.   :2018-11-30                                Max.   :36149  \n    Rainfall         Snowfall           Temp            Humidity    \n Min.   : 0.000   Min.   : 0.000   Min.   :-14.738   Min.   :22.25  \n 1st Qu.: 0.000   1st Qu.: 0.000   1st Qu.:  3.304   1st Qu.:47.58  \n Median : 0.000   Median : 0.000   Median : 13.738   Median :57.17  \n Mean   : 3.576   Mean   : 1.863   Mean   : 12.776   Mean   :58.17  \n 3rd Qu.: 0.500   3rd Qu.: 0.000   3rd Qu.: 22.592   3rd Qu.:67.71  \n Max.   :95.500   Max.   :78.700   Max.   : 33.742   Max.   :95.88  \n   WindSpeed        Visibility        DewTemp           SolarRad      \n Min.   :0.6625   Min.   : 214.3   Min.   :-27.750   Min.   :0.02917  \n 1st Qu.:1.3042   1st Qu.:1087.0   1st Qu.: -5.188   1st Qu.:0.28333  \n Median :1.6583   Median :1557.8   Median :  4.612   Median :0.56500  \n Mean   :1.7261   Mean   :1434.0   Mean   :  3.954   Mean   :0.56773  \n 3rd Qu.:1.9542   3rd Qu.:1874.3   3rd Qu.: 14.921   3rd Qu.:0.82000  \n Max.   :4.0000   Max.   :2000.0   Max.   : 25.038   Max.   :1.21667  \n\n\nOnce again, nothing looks out of the ordinary.\n\n\nPlots of Response and Predictors\nI plan to model using RentedBikeCount as the response variable. Let’s go ahead and create plots for all of the numeric predictors versus RentedBikeCount.\n\nseoulbike_new_model &lt;- seoulbike_new |&gt;\n  ungroup()\n\npar(mfrow=c(3,3))\n\nplot(seoulbike_new_model$Rainfall, seoulbike_new_model$RentedBikeCount,\n     xlab = \"Rainfall\", ylab = \"Rented Bike Count\", main = \"Rainfall vs Rented Bike Count\")\nabline(lm(seoulbike_new_model$RentedBikeCount ~ seoulbike_new_model$Rainfall), col = \"red\")\n\nplot(seoulbike_new_model$Snowfall, seoulbike_new_model$RentedBikeCount,\n     xlab = \"Snowfall\", ylab = \"Rented Bike Count\", main = \"Snowfall vs Rented Bike Count\")\nabline(lm(seoulbike_new_model$RentedBikeCount ~ seoulbike_new_model$Snowfall), col = \"red\")\n\nplot(seoulbike_new_model$Temp, seoulbike_new_model$RentedBikeCount,\n     xlab = \"Temperature\", ylab = \"Rented Bike Count\", main = \"Temperature vs Rented Bike Count\")\nabline(lm(seoulbike_new_model$RentedBikeCount ~ seoulbike_new_model$Temp), col = \"red\")\n\nplot(seoulbike_new_model$Humidity, seoulbike_new_model$RentedBikeCount,\n     xlab = \"Humidity\", ylab = \"Rented Bike Count\", main = \"Humidity vs Rented Bike Count\")\nabline(lm(seoulbike_new_model$RentedBikeCount ~ seoulbike_new_model$Humidity), col = \"red\")\n\nplot(seoulbike_new_model$WindSpeed, seoulbike_new_model$RentedBikeCount,\n     xlab = \"Wind Speed\", ylab = \"Rented Bike Count\", main = \"Wind Speed vs Rented Bike Count\")\nabline(lm(seoulbike_new_model$RentedBikeCount ~ seoulbike_new_model$WindSpeed), col = \"red\")\n\nplot(seoulbike_new_model$Visibility, seoulbike_new_model$RentedBikeCount,\n     xlab = \"Visibility\", ylab = \"Rented Bike Count\", main = \"Visibility vs Rented Bike Count\")\nabline(lm(seoulbike_new_model$RentedBikeCount ~ seoulbike_new_model$Visibility), col = \"red\")\n\nplot(seoulbike_new_model$DewTemp, seoulbike_new_model$RentedBikeCount,\n     xlab = \"Dew Temperature\", ylab = \"Rented Bike Count\", main = \"Dew Temperature vs Rented Bike Count\")\nabline(lm(seoulbike_new_model$RentedBikeCount ~ seoulbike_new_model$DewTemp), col = \"red\")\n\nplot(seoulbike_new_model$SolarRad, seoulbike_new_model$RentedBikeCount,\n     xlab = \"Solar Radiation\", ylab = \"Rented Bike Count\", main = \"Solar Radiation vs Rented Bike Count\")\nabline(lm(seoulbike_new_model$RentedBikeCount ~ seoulbike_new_model$SolarRad), col = \"red\")\n\n\n\n\nThe most useful predictors seem to be Temperature, Solar Radiation, and Dew Temperature. That makes sense, since warmer weathers would warrant more people wanting to buy bikes.\n\n\nCorrelation Between Numeric Variables\n\nseoulbike_new_model |&gt; \n  select(where(is.numeric)) |&gt;\n  mutate(across(everything(), as.numeric)) |&gt;\n  cor(use = \"complete.obs\") |&gt;\n  corrplot(\n    method = \"circle\", \n    type = \"upper\", \n    tl.col = \"red\", \n    tl.srt = 45, \n    addCoef.col = \"black\", \n    col = colorRampPalette(c(\"cyan\", \"white\", \"salmon\"))(200)\n  )\n\n\n\n\nSome of the predictors are highly correlated. Those same 3 useful predictors pop up again, but we definitely expect to see some of these high predictors in our final models.\n\n\n\nTask 2: Modeling\n\nTest Train Split\nCreating the test train split with strata of seasons. This lets us account to make sure we don’t overfit later!\n\ndata_split &lt;- initial_split(seoulbike_new_model, prop = 0.75, strata = \"Seasons\")\ntrain_data &lt;- training(data_split)\ntest_data &lt;- testing(data_split)\n\ncv_folds &lt;- vfold_cv(train_data, v = 10)\n\n\n\nRecipe 1\nIn this recipe, we create dummy variable and standardize the numeric scales. This one is kept relatively simple!\n\nrec_1 &lt;- recipe(RentedBikeCount~ ., data = train_data) |&gt; \n  step_mutate(dow = weekdays(Date))|&gt;\n  step_mutate(Day = factor(if_else(dow %in% c(\"Saturday\", \"Sunday\"), \"Weekend\", \"Weekday\"))) |&gt; \n  step_select(-Date, -dow) |&gt; \n  step_normalize(all_numeric()) |&gt; \n  step_dummy(Seasons, Holiday, Day)\n\n\n  #prep(training = train_data) |&gt; \n  #bake(train_data)\n\n\n\nRecipe 2\nThis builds on the first recipe, introducing interactions where necessary.\n\nrec_2 &lt;- recipe(RentedBikeCount~ ., data = train_data) |&gt;\n  step_mutate(dow = weekdays(Date)) |&gt;\n  step_mutate(Day = factor(if_else(dow %in% c(\"Saturday\", \"Sunday\"), \"Weekend\", \"Weekday\"))) |&gt; \n  step_select(-Date, -dow) |&gt; \n  step_normalize(all_numeric()) |&gt; \n  step_dummy(Seasons, Holiday, Day) |&gt; \n  step_interact(terms = ~ starts_with(\"Seasons\"):starts_with(\"Holiday\")) |&gt; \n  step_interact(terms = ~ starts_with(\"Seasons\"):starts_with(\"Temp\")) |&gt; \n  step_interact(terms = ~ starts_with(\"Temp\"):starts_with(\"Rainfall\"))\n  #prep(training = train_data) |&gt; \n  #bake(train_data)\n\n\n\nRecipe 3\nThis builds on recipe 1 and 2, adding quadratic terms for each numeric predictor.\n\nrec_3 &lt;- recipe(RentedBikeCount~., data = train_data) |&gt;\n  step_mutate(dow = weekdays(Date)) |&gt;\n  step_mutate(Day = factor(if_else(dow %in% c(\"Saturday\", \"Sunday\"), \"Weekend\", \"Weekday\"))) |&gt; \n  step_select(-Date, -dow) |&gt; \n  step_normalize(all_numeric()) |&gt; \n  step_dummy(Seasons, Holiday, Day) |&gt; \n  step_interact(terms = ~ starts_with(\"Seasons\"):starts_with(\"Holiday\")) |&gt; \n  step_interact(terms = ~ starts_with(\"Seasons\"):starts_with(\"Temp\")) |&gt; \n  step_interact(terms = ~ starts_with(\"Temp\"):starts_with(\"Rainfall\")) |&gt; \n  step_poly(Rainfall, Snowfall, Temp, Humidity, WindSpeed, Visibility, DewTemp, SolarRad, degree = 2)\n  #prep(training = train_data) |&gt; \n  #bake(train_data)\n\n\n\nSet up Engine\nUsing set engine, we initialize bike model.\n\nbike_mod &lt;- linear_reg() |&gt;\n set_engine(\"lm\")\n\n\n\nFinal Models and Evaluate\n\nbike_CV_fits1 &lt;- workflow() |&gt;\n  add_recipe(rec_1) |&gt;\n  add_model(bike_mod) |&gt;\n  fit_resamples(cv_folds)\n\nbike_CV_fits2 &lt;- workflow() |&gt;\n  add_recipe(rec_2) |&gt;\n  add_model(bike_mod) |&gt;\n  fit_resamples(cv_folds)\n\nbike_CV_fits3 &lt;- workflow() |&gt;\n  add_recipe(rec_3) |&gt;\n  add_model(bike_mod) |&gt;\n  fit_resamples(cv_folds)\n\nrbind(bike_CV_fits1 |&gt; collect_metrics(),\n      bike_CV_fits2 |&gt; collect_metrics(),\n      bike_CV_fits3 |&gt; collect_metrics())\n\n# A tibble: 6 × 6\n  .metric .estimator  mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   0.413    10  0.0209 Preprocessor1_Model1\n2 rsq     standard   0.828    10  0.0159 Preprocessor1_Model1\n3 rmse    standard   0.538    10  0.196  Preprocessor1_Model1\n4 rsq     standard   0.821    10  0.0631 Preprocessor1_Model1\n5 rmse    standard   0.505    10  0.183  Preprocessor1_Model1\n6 rsq     standard   0.835    10  0.0614 Preprocessor1_Model1\n\n\nFrom this, we can see that the best model is Fit 1, the simple model. The RMSE is the smallest, and even though the \\(R^2\\) is the largest for the 3rd model, it looks like it is overfit.\n\n\nFit Model on Entire Training Set and Evaluate on Test Set\n\nbest_fit &lt;- workflow() |&gt;\n  add_recipe(rec_1) |&gt;\n  add_model(bike_mod) |&gt;\n  last_fit(split = data_split)\n\nbest_fit |&gt; collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard       0.424 Preprocessor1_Model1\n2 rsq     standard       0.831 Preprocessor1_Model1\n\n\nExcellent! Looks like the model fits well.\n\n\nFinal Coefficients\n\nbest_fit |&gt; extract_fit_parsnip() |&gt;  tidy()\n\n# A tibble: 14 × 5\n   term               estimate std.error statistic  p.value\n   &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)          0.0822    0.131      0.628 5.30e- 1\n 2 Rainfall            -0.191     0.0333    -5.72  3.04e- 8\n 3 Snowfall            -0.0277    0.0273    -1.02  3.10e- 1\n 4 Temp                -0.801     0.470     -1.70  9.00e- 2\n 5 Humidity            -0.423     0.179     -2.36  1.90e- 2\n 6 WindSpeed           -0.0687    0.0292    -2.35  1.94e- 2\n 7 Visibility          -0.0338    0.0359    -0.942 3.47e- 1\n 8 DewTemp              1.39      0.553      2.51  1.29e- 2\n 9 SolarRad             0.436     0.0469     9.29  8.09e-18\n10 Seasons_Spring      -0.548     0.0818    -6.70  1.36e-10\n11 Seasons_Summer      -0.386     0.103     -3.76  2.11e- 4\n12 Seasons_Winter      -0.837     0.108     -7.73  2.60e-13\n13 Holiday_No.Holiday   0.473     0.123      3.86  1.47e- 4\n14 Day_Weekend         -0.278     0.0566    -4.91  1.66e- 6"
  }
]